# ğŸ¯ RL-Based A/B/n Testing

A practical, plug-and-play framework to run **real-time A/B/n testing** using **Reinforcement Learning (Multi-Armed Bandits)**. Supports Epsilon-Greedy, UCB, and Thompson Sampling agents, both in **live deployments** (via FastAPI + Redis) and **offline simulations**.

---

## ğŸ§  Why Reinforcement Learning for A/B/n Testing?

Traditional A/B testing wastes traffic by allocating equally or randomly. RL-based approaches adaptively shift traffic to better-performing variants, increasing engagement during testing â€” not just after.

---

## ğŸ“¦ Installation

> âš™ï¸ Requires Python 3.10+ (tested on 3.10/3.11/3.13), and Redis installed locally or via Docker.

### 1. Clone the repo
```bash
git clone https://github.com/vizz1234/RL_ABn_testing.git
cd RL-AB-testing
```

## ğŸ“¦ Installation

### 1. Install Python dependencies

```bash
pip install -r requirements.txt
```
### 2. Start Redis server
If installed locally:

```bash
brew services start redis
```

## ğŸ—‚ Project Structure

```
RL-AB-testing/
â”œâ”€â”€ main.py                  # FastAPI app for real-time testing
â”œâ”€â”€ config.py                # App config (epsilon, Redis, etc.)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html           # Jinja2 template to serve variants
â”œâ”€â”€ eGreedy.py               # Online Epsilon-Greedy agent
â”œâ”€â”€ UCB.py                   # Online UCB agent
â”œâ”€â”€ thompsonSampling.py      # Online Thompson Sampling agent
â”œâ”€â”€ simulate/
â”‚   â”œâ”€â”€ eGreedy.py           # Offline simulation for e-Greedy
â”‚   â”œâ”€â”€ UCB.py               # Offline simulation for UCB
â”‚   â”œâ”€â”€ thompsonSampling.py  # Offline simulation for Thompson Sampling
â”œâ”€â”€ requirements.txt         # Minimal project dependencies
â””â”€â”€ README.md                # You're reading it.
```

## ğŸš€ Running the Live App
This app mimics a web experiment where users are shown different variants.

```
fastapi dev main.py
```

Then open http://localhost:8000 â€” each refresh mimics a new user. Behind the scenes, the selected agent (e.g., Îµ-Greedy) updates estimates and shifts traffic in real-time, backed by Redis. 

Go to http://localhost:8000/stats for viewing metrics of each variant.


## ğŸ“Š Simulation Mode (Offline)
To visualize how each agent behaves in controlled setups, run:

```
cd simulate
python eGreedy.py
python UCB.py
python thompsonSampling.py
```

Each script:

Runs 1000 simulated users.

Logs views and estimates per variant. 

Displays an animation of progression of each variant over time.

